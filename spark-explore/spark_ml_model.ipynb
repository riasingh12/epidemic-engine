{"cells": [{"cell_type": "code", "execution_count": 1, "id": "a562d7c8-d6fa-4c56-9426-5e981b720507", "metadata": {}, "outputs": [], "source": "import datetime\nfrom numpy import array, sqrt\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, udf, unix_timestamp, expr, when\nfrom pyspark.sql.types import FloatType\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.clustering import KMeans\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\nfrom pyspark.ml.evaluation import ClusteringEvaluator, MulticlassClassificationEvaluator, BinaryClassificationEvaluator\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n"}, {"cell_type": "code", "execution_count": 2, "id": "02235a2f-f7f0-4642-9bde-7da1e4b95901", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/05/09 16:43:43 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n24/05/09 16:43:43 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- EventType: string (nullable = true)\n |-- Timestamp: timestamp (nullable = true)\n |-- Location: string (nullable = true)\n |-- Severity: string (nullable = true)\n |-- Details: string (nullable = true)\n |-- Is_Anomaly: integer (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 2:=============================>                             (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "This datasets consists of 1000000 rows.\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "\n\n# Initialize Spark Session\nspark = SparkSession.builder \\\n    .appName(\"Anomaly Detection Model\") \\\n    .getOrCreate()\nspark = SparkSession.builder \\\n    .appName(\"KafkaDataSparkAnalysis\") \\\n    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0\") \\\n    .getOrCreate()\n\n# the following line gets the bucket name attached to our cluster\nbucket = spark._jsc.hadoopConfiguration().get(\"fs.gs.system.bucket\")\n\n# specifying the path to our bucket where the data is located (no need to edit this path anymore)\ndata = \"gs://\" + bucket + \"/notebooks/jupyter/\"\n\ndf = spark.read.format(\"csv\")\\\n    .option(\"header\", \"true\")\\\n    .option(\"inferSchema\", \"true\")\\\n    .load(data + \"data.csv\")\\\n    .coalesce(5)\n\n\n# df = df.withColumn(\"timestamp_unix\", unix_timestamp(\"Timestamp\"))\n\n\ndf.cache()\ndf.printSchema()\nprint(\"This datasets consists of {} rows.\".format(df.count()))\n"}, {"cell_type": "code", "execution_count": 3, "id": "802844d7-f79d-4931-96af-195bc25abb5e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------+-------------------+-----------+--------+--------------------+----------+\n|           EventType|          Timestamp|   Location|Severity|             Details|Is_Anomaly|\n+--------------------+-------------------+-----------+--------+--------------------+----------+\n|  emergency_incident|2022-01-01 00:00:00|     Boston|    high|This is a simulat...|         0|\n|      health_mention|2022-01-01 00:01:00|      Tokyo|     low|This is a simulat...|         0|\n|      health_mention|2022-01-01 00:01:00|      Tokyo|  medium|This is a simulat...|         0|\n|         vaccination|2022-01-01 00:01:00|     Boston|  medium|This is a simulat...|         0|\n|general_health_re...|2022-01-01 00:03:00|      Tokyo|  medium|This is a simulat...|         0|\n|  hospital_admission|2022-01-01 00:03:00|    Chicago|  medium|This is a simulat...|         0|\n|general_health_re...|2022-01-01 00:03:00|    Chicago|  medium|This is a simulat...|         0|\n|general_health_re...|2022-01-01 00:05:00|Los Angeles|  medium|This is a simulat...|         0|\n|      health_mention|2022-01-01 00:06:00|      Paris|  medium|This is a simulat...|         0|\n|general_health_re...|2022-01-01 00:07:00|      Paris|  medium|This is a simulat...|         0|\n|      health_mention|2022-01-01 00:08:00|   New York|     low|This is a simulat...|         0|\n|      health_mention|2022-01-01 00:09:00|    Chicago|  medium|This is a simulat...|         0|\n|  hospital_admission|2022-01-01 00:10:00|    Chicago|    high|This is a simulat...|         0|\n|general_health_re...|2022-01-01 00:10:00|     Berlin|  medium|This is a simulat...|         0|\n|general_health_re...|2022-01-01 00:11:00|     Berlin|  medium|This is a simulat...|         0|\n|     routine_checkup|2022-01-01 00:13:00|   Bordeaux|     low|This is a simulat...|         0|\n|general_health_re...|2022-01-01 00:15:00|     Berlin|  medium|This is a simulat...|         0|\n|  hospital_admission|2022-01-01 00:17:00|      Paris|    high|This is a simulat...|         0|\n|  emergency_incident|2022-01-01 00:19:00|   New York|    high|This is a simulat...|         0|\n|         vaccination|2022-01-01 00:20:00|      Tokyo|  medium|This is a simulat...|         0|\n|general_health_re...|2022-01-01 00:20:00|      Tokyo|  medium|This is a simulat...|         0|\n|general_health_re...|2022-01-01 00:22:00|   Bordeaux|  medium|This is a simulat...|         0|\n|  hospital_admission|2022-01-01 00:23:00|   Bordeaux|  medium|This is a simulat...|         0|\n|         vaccination|2022-01-01 00:24:00|     Berlin|     low|This is a simulat...|         0|\n|  hospital_admission|2022-01-01 00:25:00|Los Angeles|  medium|This is a simulat...|         0|\n+--------------------+-------------------+-----------+--------+--------------------+----------+\nonly showing top 25 rows\n\n"}], "source": "df.show(25)"}, {"cell_type": "code", "execution_count": 4, "id": "78c0ac8f-6d3f-4d32-b492-f4ca9064b310", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Training data size: 700072\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 9:=============================>                             (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "Testing data size: 299928\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "\ntrain_df, test_df = df.randomSplit([0.7, 0.3], seed=42)\nprint(\"Training data size: {}\".format(train_df.count()))\nprint(\"Testing data size: {}\".format(test_df.count()))"}, {"cell_type": "code", "execution_count": 5, "id": "e05b2459-c7e8-4a80-a261-dcbb6ff2c582", "metadata": {}, "outputs": [], "source": "\n# Index and encode categorical features\nindexer_event = StringIndexer(inputCol=\"EventType\", outputCol=\"EventType_Index\")\nindexer_location = StringIndexer(inputCol=\"Location\", outputCol=\"Location_Index\")\n\n# Convert 'Severity' to a numerical scale\nseverity_scale = {\"low\": 1, \"medium\": 2, \"high\": 3}\ntrain_df = train_df.withColumn(\"Severity_Num\", when(col(\"Severity\") == \"low\", severity_scale[\"low\"])\n                                                        .when(col(\"Severity\") == \"medium\", severity_scale[\"medium\"])\n                                                        .when(col(\"Severity\") == \"high\", severity_scale[\"high\"]))\ntest_df = test_df.withColumn(\"Severity_Num\", when(col(\"Severity\") == \"low\", severity_scale[\"low\"])\n                                                      .when(col(\"Severity\") == \"medium\", severity_scale[\"medium\"])\n                                                      .when(col(\"Severity\") == \"high\", severity_scale[\"high\"]))\n"}, {"cell_type": "code", "execution_count": 6, "id": "61ab77d3-1148-4bca-b36f-7191a46206f9", "metadata": {}, "outputs": [], "source": "\n# Assemble features into a single vector column\nassembler = VectorAssembler(inputCols=[\"EventType_Index\", \"Location_Index\", \"Severity_Num\"], outputCol=\"features\")\n\n# Scale the features\nscaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n"}, {"cell_type": "code", "execution_count": 7, "id": "a6f55f6c-ee3c-4981-8b93-455bfaefe34d", "metadata": {}, "outputs": [], "source": "\n# Define the KMeans model\nkmeans = KMeans().setK(9).setSeed(7).setFeaturesCol(\"scaledFeatures\")\n\n# Build the pipeline\npipeline = Pipeline(stages=[indexer_event, indexer_location, assembler, scaler, kmeans])\n"}, {"cell_type": "code", "execution_count": 8, "id": "2c3d8594-b4d3-4dc7-b49f-87859cd24bc9", "metadata": {}, "outputs": [], "source": "\n# Define a parameter grid\nparamGrid = (ParamGridBuilder()\n             .addGrid(kmeans.k, [12])  # Number of clusters\n             .addGrid(scaler.withStd, [True, False])  # Standard deviation scaling\n             .build())\n"}, {"cell_type": "code", "execution_count": 9, "id": "cdd3a63b-7a0b-4403-ad3c-2d4e435d96ae", "metadata": {}, "outputs": [], "source": "\n# Define the evaluator\nevaluator = ClusteringEvaluator(predictionCol=\"prediction\", featuresCol=\"scaledFeatures\", metricName=\"silhouette\")\n"}, {"cell_type": "code", "execution_count": 10, "id": "9a5ab02c-59a1-44b7-a2aa-182e29773446", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "\n# Set up the CrossValidator\ncrossval = CrossValidator(estimator=pipeline,\n                          estimatorParamMaps=paramGrid,\n                          evaluator=evaluator,\n                          numFolds=9)  # Adjusted for demonstration\n\n# Run cross-validation on the training data, and choose the best set of parameters.\ncvModel = crossval.fit(train_df)"}, {"cell_type": "code", "execution_count": 11, "id": "78ade871-8660-453f-a05e-b3b55ec10771", "metadata": {}, "outputs": [], "source": "# Fetch the best model\nbestModel = cvModel.bestModel\nbestKMeansModel = bestModel.stages[-1]  # The last stage is KMeans in the pipeline"}, {"cell_type": "code", "execution_count": 12, "id": "d3d56617-91da-4b21-afba-acaadf057dbd", "metadata": {}, "outputs": [], "source": "# Make predictions on the test data\npredictions = bestModel.transform(test_df)"}, {"cell_type": "code", "execution_count": 13, "id": "808daaa5-6379-427e-adce-a875a83a13cc", "metadata": {}, "outputs": [], "source": "# Now choose an anomaly cluster as before (this part would be manual and interpretive)\nanomaly_cluster = 1  # This needs to be checked based on new cluster centers\npredictions = predictions.withColumn(\"predicted_label\", (col(\"prediction\") == anomaly_cluster).cast(\"double\"))"}, {"cell_type": "code", "execution_count": 14, "id": "5b4288a1-5e20-451a-ab4f-7ff18dddf21b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------------+-------------------+-----------+--------+--------------------+----------+------------+---------------+--------------+-------------+--------------------+----------+---------------+\n|         EventType|          Timestamp|   Location|Severity|             Details|Is_Anomaly|Severity_Num|EventType_Index|Location_Index|     features|      scaledFeatures|prediction|predicted_label|\n+------------------+-------------------+-----------+--------+--------------------+----------+------------+---------------+--------------+-------------+--------------------+----------+---------------+\n|emergency_incident|2022-01-01 00:31:00|   New York|    high|This is a simulat...|         0|           3|            3.0|           5.0|[3.0,5.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 00:42:00|Los Angeles|    high|This is a simulat...|         0|           3|            3.0|           4.0|[3.0,4.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 00:47:00|    Chicago|    high|This is a simulat...|         0|           3|            3.0|           3.0|[3.0,3.0,3.0]|[1.75582044243775...|         2|            0.0|\n|emergency_incident|2022-01-01 00:54:00|    Chicago|    high|This is a simulat...|         0|           3|            3.0|           3.0|[3.0,3.0,3.0]|[1.75582044243775...|         2|            0.0|\n|emergency_incident|2022-01-01 01:15:00|   New York|    high|This is a simulat...|         0|           3|            3.0|           5.0|[3.0,5.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 01:19:00|     Boston|    high|This is a simulat...|         0|           3|            3.0|           2.0|[3.0,2.0,3.0]|[1.75582044243775...|         2|            0.0|\n|emergency_incident|2022-01-01 01:20:00|      Tokyo|    high|This is a simulat...|         0|           3|            3.0|           1.0|[3.0,1.0,3.0]|[1.75582044243775...|         2|            0.0|\n|emergency_incident|2022-01-01 01:48:00|    Chicago|    high|This is a simulat...|         0|           3|            3.0|           3.0|[3.0,3.0,3.0]|[1.75582044243775...|         2|            0.0|\n|emergency_incident|2022-01-01 02:01:00|   Bordeaux|    high|This is a simulat...|         0|           3|            3.0|           7.0|[3.0,7.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 02:15:00|   New York|    high|This is a simulat...|         0|           3|            3.0|           5.0|[3.0,5.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 02:18:00|      Paris|    high|This is a simulat...|         0|           3|            3.0|           6.0|[3.0,6.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 02:54:00|     Berlin|    high|This is a simulat...|         0|           3|            3.0|           0.0|[3.0,0.0,3.0]|[1.75582044243775...|         2|            0.0|\n|emergency_incident|2022-01-01 02:56:00|Los Angeles|    high|This is a simulat...|         0|           3|            3.0|           4.0|[3.0,4.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 02:57:00|     Berlin|    high|This is a simulat...|         0|           3|            3.0|           0.0|[3.0,0.0,3.0]|[1.75582044243775...|         2|            0.0|\n|emergency_incident|2022-01-01 03:05:00|Los Angeles|    high|This is a simulat...|         0|           3|            3.0|           4.0|[3.0,4.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 03:24:00|   New York|    high|This is a simulat...|         0|           3|            3.0|           5.0|[3.0,5.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 03:25:00|      Tokyo|    high|This is a simulat...|         0|           3|            3.0|           1.0|[3.0,1.0,3.0]|[1.75582044243775...|         2|            0.0|\n|emergency_incident|2022-01-01 03:49:00|Los Angeles|    high|This is a simulat...|         0|           3|            3.0|           4.0|[3.0,4.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 04:03:00|Los Angeles|    high|This is a simulat...|         0|           3|            3.0|           4.0|[3.0,4.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 04:06:00|   New York|    high|This is a simulat...|         0|           3|            3.0|           5.0|[3.0,5.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 04:12:00|     Boston|    high|This is a simulat...|         0|           3|            3.0|           2.0|[3.0,2.0,3.0]|[1.75582044243775...|         2|            0.0|\n|emergency_incident|2022-01-01 04:19:00|      Paris|    high|This is a simulat...|         0|           3|            3.0|           6.0|[3.0,6.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 04:22:00|      Tokyo|    high|This is a simulat...|         0|           3|            3.0|           1.0|[3.0,1.0,3.0]|[1.75582044243775...|         2|            0.0|\n|emergency_incident|2022-01-01 04:47:00|Los Angeles|    high|This is a simulat...|         0|           3|            3.0|           4.0|[3.0,4.0,3.0]|[1.75582044243775...|         4|            0.0|\n|emergency_incident|2022-01-01 04:58:00|   New York|    high|This is a simulat...|         0|           3|            3.0|           5.0|[3.0,5.0,3.0]|[1.75582044243775...|         4|            0.0|\n+------------------+-------------------+-----------+--------+--------------------+----------+------------+---------------+--------------+-------------+--------------------+----------+---------------+\nonly showing top 25 rows\n\n"}], "source": "predictions.show(25)"}, {"cell_type": "code", "execution_count": 15, "id": "5bfa8e14-b102-4934-99b8-756d580c4381", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 657:>                                                        (0 + 2) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "Best number of clusters: 12\nAccuracy: 0.9371682537142247\nF1 Score: 0.9673765009491587\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "\n# Calculate Accuracy and F1 Score (as before, or consider using binary evaluators)\nevaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"Is_Anomaly\", predictionCol=\"predicted_label\", metricName=\"accuracy\")\naccuracy = evaluator_accuracy.evaluate(predictions)\n\nevaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"Is_Anomaly\", predictionCol=\"predicted_label\", metricName=\"f1\")\nf1_score = evaluator_f1.evaluate(predictions)\n\nprint(f\"Best number of clusters: {bestKMeansModel.getK()}\")\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"F1 Score: {f1_score}\")\n"}, {"cell_type": "code", "execution_count": null, "id": "7c48292b-cc3f-4ce7-9767-119b82dc5132", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 5}